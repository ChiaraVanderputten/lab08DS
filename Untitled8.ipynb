{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1cgUc0vy6lZru4st2u/ck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiaraVanderputten/lab08DS/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmJ5CgicMWo"
      },
      "source": [
        "#2.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mRkoNmWcOjn"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def f1(x):\n",
        " return x*np.sin(x)+(2*x)\n",
        "\n",
        "def f2(x):\n",
        " return 10*np.sin(x)+(x**2)\n",
        "\n",
        "def f3(x):\n",
        " return np.sign(x)*((x**2)+300) + 20*np.sin(x)\n",
        "\n",
        "for f in [f1, f2, f3]:\n",
        " tr = 20\n",
        " n_samples = 100\n",
        " X = np.linspace(-tr, tr, n_samples)\n",
        " y = f(X)\n",
        " X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=0.7, random_state=42, shuffle=True)\n",
        " y_test = y_test[X_test.argsort()]\n",
        " X_test.sort()\n",
        " plt.plot(X, y, marker = \"o\", color = 'red')\n",
        " plt.xlabel(\"X\") \n",
        " plt.ylabel(\"y\")\n",
        " plt.title(f)\n",
        " plt.show()\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures\n",
        "\n",
        "def creoValori(f,X,y):\n",
        " tr = 20\n",
        " n_samples = 100\n",
        " X = np.linspace(-tr, tr, n_samples)\n",
        " y = f(X)\n",
        " X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=0.7, random_state=42, shuffle=True)\n",
        " y_test = y_test[X_test.argsort()]\n",
        " X_test.sort()\n",
        " return  X_train, X_test, y_train, y_test\n",
        " \n",
        "\n",
        "def valutazioneModello(f,X,y, model):\n",
        "   X_train, X_test, y_train, y_test = creoValori(f,X,y)\n",
        "   fig, ax = plt.subplots()\n",
        "   ax.plot(X, y, color='cornflowerblue', linewidth=.5*2, label=\"ground truth\")\n",
        "   ax.scatter(X_train, y_train, color='navy', s=30, marker='o', label=\"training points\")\n",
        "\n",
        "   if(model==LinearRegression()):\n",
        "    make_pipeline(PolynomialFeatures(4), model).fit(X_train.reshape(-1, 1),y_train)\n",
        "   else:  \n",
        "    model.fit(X_train.reshape(-1, 1),y_train)\n",
        "    y_test_pred = model.predict(X_test.reshape(-1, 1))\n",
        "    r2 = r2_score(y_test, y_test_pred)\n",
        "    mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    mse= mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "   ax.plot(X_test, y_test_pred, linewidth=2, label=model, color='r')\n",
        "   fig.suptitle(f\"{f} approximated by {model}\")\n",
        "   fig.legend()\n",
        "\n",
        "   return r2,mae,mse\n",
        "\n",
        "modelli =[LinearRegression(),Ridge( random_state=42), SVR(), RandomForestRegressor(), MLPRegressor(random_state=42) ]\n",
        "\n",
        "\n",
        "for model in modelli:\n",
        "    r,m1,m2 = valutazioneModello(f1,X,y, model)\n",
        "    print(f, model, \"R squared : \", r, \"mean absolute error : \", m1, \"mean squared error : \", m2)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.2"
      ],
      "metadata": {
        "id": "dcP3zlr_hGY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "X, y = make_regression(n_samples=2000, random_state=42)\n",
        "\n",
        "t = PrettyTable()\n",
        "t.field_names = ['model', 'MSE', 'R2']\n",
        "\n",
        "modelli =[LinearRegression(),Ridge( random_state=42), SVR(), RandomForestRegressor(), MLPRegressor(random_state=42) ]\n",
        "nomi=['regressione lineare', 'ridge', 'SVR', 'Random Forest', 'MLPRegressor']\n",
        "\n",
        "\n",
        "for model, name in zip(modelli, nomi):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=30,random_state=42,shuffle=True)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "  t.add_row([name, mse, r2])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46L95xhuhIrK",
        "outputId": "badd6faa-4dbb-4865-dda6-c271b3f5d971"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------------------+----------------------+\n",
            "|        model        |        MSE         |          R2          |\n",
            "+---------------------+--------------------+----------------------+\n",
            "| regressione lineare | 29476.84849465286  | 0.24664307356115445  |\n",
            "|        ridge        | 29531.736706152406 | 0.24524026368069773  |\n",
            "|         SVR         | 42978.44017575457  | -0.09842494185956463 |\n",
            "|    Random Forest    | 33538.72761379126  |  0.1428312712473715  |\n",
            "|     MLPRegressor    | 36337.97148201045  | 0.07128937092186904  |\n",
            "+---------------------+--------------------+----------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    }
  ]
}